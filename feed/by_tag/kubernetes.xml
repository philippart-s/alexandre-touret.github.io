<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="https://blog.touret.info/feed/by_tag/kubernetes.xml" rel="self" type="application/atom+xml" /><link href="https://blog.touret.info/" rel="alternate" type="text/html" /><updated>2022-07-09T17:05:11+00:00</updated><id>https://blog.touret.info/feed/by_tag/kubernetes.xml</id><title type="html">blog.touret.info</title><subtitle>Mon blog personnel. J'y expose mes derniers travaux et ma veille technologique. Au menu en vrac: Java, Kotlin, Maven, Docker, Cloud, Kubernetes, logiciels libres, Debian, Ubuntu, Gnu/Linux, des talks online et présentiels.</subtitle><author><name>Alexandre Touret</name></author><entry><title type="html">Faire des batchs “Cloud Native” dans Kubernetes</title><link href="https://blog.touret.info/2022/05/17/cloud-native-batchs/" rel="alternate" type="text/html" title="Faire des batchs “Cloud Native” dans Kubernetes" /><published>2022-05-17T08:00:00+00:00</published><updated>2022-05-17T08:00:00+00:00</updated><id>https://blog.touret.info/2022/05/17/cloud-native-batchs</id><content type="html" xml:base="https://blog.touret.info/2022/05/17/cloud-native-batchs/">&lt;p&gt;Quand on parle du Cloud et de Kubernetes, généralement on pense aux APIs.
Mais qu’en est-il des batchs?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2022/05/pat-whelen-xSsWBa4rb6E-unsplash.webp&quot; alt=&quot;pat-whelen-xSsWBa4rb6E-unsplash.jpg &quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Oui, depuis plusieurs années, on pensait les éradiquer, mais ils sont encore là et on en a encore besoin pour quelques années encore. 
Ils ont même eu une deuxième jeunesse avec le Big Data et l’explosion des volumétries dans l’IT.&lt;/p&gt;

&lt;p&gt;Je vais essayer de faire un tour d’horizon dans cet article des batchs dans un environnement Cloud et plus particulièrement dans Kubernetes.&lt;/p&gt;

&lt;p&gt;Les exemples présentés dans cet article seront (sans doute) approfondis dans un second article et d’ores et déjà disponibles dans &lt;a href=&quot;https://github.com/alexandre-touret/k8s-batch&quot;&gt;mon GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;pourquoi-des-batchs-dans-le-cloud&quot;&gt;Pourquoi des batchs dans le Cloud?&lt;/h2&gt;

&lt;p&gt;A ce titre un peu provocateur, j’ajouterais aussi &lt;em&gt;“Pourquoi des batchs dans Kubernetes ?”&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Oui, aujourd’hui encore,comme j’ai pu l’indiquer précédemment, on doit créer des traitements batchs. A coté des APIs qui représentent le cas d’utilisation “standard” du Cloud, on peut également avoir à traiter des fichiers volumineux allant de plusieurs centaines de Mo à quelques Go.&lt;/p&gt;

&lt;p&gt;Parmi les cas d’utilisation qui nécessitent ce genre de traitement, on pourra avoir:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Les reprises de données (suite à des erreurs ou lors d’une initialisation)&lt;/li&gt;
  &lt;li&gt;Traitement suite à une réception de fichiers (par ex. traitement de fichiers OPENDATA)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Si vous êtes déjà passé sur le Cloud pour vos applications transactionnelles, vous vous poserez cette question: &lt;em&gt;Puis-je également déployer des batchs?&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;pourquoi-se-poser-cette-question&quot;&gt;Pourquoi se poser cette question?&lt;/h3&gt;

&lt;p&gt;Les réponses sont multiples. 
Elles sont tout d’abord liées à une rationalisation des environnements.
Vous avez votre application dans le cloud, votre base de données y est également gérée pour éviter la latence réseau.
Vous devez donc déployer des traitements tiers au plus proche de celle-ci pour vous soustraire des mêmes soucis.&lt;/p&gt;

&lt;p&gt;De plus, l’écosystème lié au cloud offre des technologies et pratiques qui rendent la vie plus simple (si, si, je vous assure) aux développeurs et ops. 
Le déploiement via &lt;a href=&quot;https://en.wikipedia.org/wiki/Infrastructure_as_code&quot;&gt;l’Infra As Code&lt;/a&gt; est un bon exemple : Avoir toute l’infrastructure liée aux traitements batchs et transactionnels versionnées et instantiables à la demande est quelque chose dont on a du mal à se passer!&lt;/p&gt;

&lt;h2 id=&quot;difficultés-par-rapport-aux-apis&quot;&gt;Difficulté(s) par rapport aux APIs&lt;/h2&gt;

&lt;p&gt;Quand on déploie une API dans le cloud, généralement tout va bien. 
On peut voir rapidement que cet environnement convient bien à ce genre de traitements.&lt;/p&gt;

&lt;p&gt;Pour les batchs, c’est une autre affaire!
Selon les sociétés, il peut y avoir un fort historique et beaucoup plus d’exigences que pour les APIs. 
Ces dernières pourront être liées aux performances, à la qualité de service ou plus simplement à l’utilisation.&lt;/p&gt;

&lt;p&gt;Il faut donc, à l’instar de toute architecture, déterminer quel sera l’environnement technique de ce type de traitement. 
Cette fois, on aura à concilier performances, fichiers volumineux et reprises sur erreur.&lt;/p&gt;

&lt;h3 id=&quot;quelques-technologies&quot;&gt;Quelques technologies&lt;/h3&gt;

&lt;p&gt;On pourra retrouver dans notre future architecture les briques suivantes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Une passerelle de fichiers (File Gateway) pour permettre l’envoi des fichiers de manière sécurisée&lt;/li&gt;
  &lt;li&gt;Un stockage objet pour la distribution de fichiers ou l’archivage.&lt;/li&gt;
  &lt;li&gt;Les éléments nécessaires à l’API : bases de données, &lt;a href=&quot;https://en.wikipedia.org/wiki/Hardware_security_module&quot;&gt;HSMs&lt;/a&gt;, Cluster Kubernetes,…&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;modes-de-déclenchement&quot;&gt;Modes de déclenchement&lt;/h2&gt;

&lt;p&gt;Si on regarde de plus près les exigences techniques liées aux cas d’utilisation, on pourrait résumer les différents modes de déclenchement de la manière suivante:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Traitement sur réception de fichiers&lt;/li&gt;
  &lt;li&gt;Traitement déclenché par un ordonnanceur/orchestrateur centralisé (ex. https://dkron.io/) de manière régulière ou non.&lt;/li&gt;
  &lt;li&gt;Traitement déclenché par &lt;a href=&quot;https://en.wikipedia.org/wiki/Cron&quot;&gt;CRON&lt;/a&gt; (qui est un ordonnanceur, mais un peu plus roots)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;J’ai volontairement exclu les traitements sur présence de messages (ex. Kafka). Je les considère plus liés au monde transactionnel.&lt;/p&gt;

&lt;p&gt;Dans les paragraphes suivants, je vais décrire des solutions d’architecture qui permettent de déployer ces traitements dans Kubernetes. J’aborderai sans doute un exemple dans un autre article&lt;/p&gt;

&lt;h2 id=&quot;contraintes&quot;&gt;Contraintes&lt;/h2&gt;

&lt;p&gt;Dès qu’on s’aventure dans ce type de conception, nous aurons, au-delà des &lt;a href=&quot;https://12factor.net/&quot;&gt;12 factors&lt;/a&gt;, les contraintes suivantes à traiter:&lt;/p&gt;

&lt;h3 id=&quot;gestion-des-erreurs-et-indisponibilités&quot;&gt;Gestion des erreurs et indisponibilités&lt;/h3&gt;
&lt;p&gt;Dans un cluster Kubernetes, le crash d’un POD n’est pas rédhibitoire.
Le cluster permet de redémarrer immédiatement une autre instance.&lt;/p&gt;

&lt;p&gt;Pour les APIs, ce n’est pas un problème.
Pour les batchs, c’est une autre paire de manches. 
Quid du crash en plein milieu du traitement d’un fichier?&lt;/p&gt;

&lt;p&gt;Il faut donc penser à ce cas (et à d’autres) et archiver les fichiers pour un éventuel rejeu.&lt;/p&gt;

&lt;h3 id=&quot;données-et-idempotence-des-traitements&quot;&gt;Données et idempotence des traitements&lt;/h3&gt;

&lt;p&gt;Idéalement, les fichiers doivent avoir des lignes indépendantes qui peuvent être insérées individuellement et dans n’importe quel ordre.
Aussi, chaque modification et traitement de données doivent être idempotentes.&lt;/p&gt;

&lt;p&gt;Pourquoi? Pas seulement par ce que c’est sympa et l’état de l’art, mais dans ce nouvel environnement, vous ne pourrez pas forcément garantir l’ordre des traitements.
L’une des solutions potentielles de traitement est de découpler la lecture et l’insertion par du queueing (Artemis, Kafka &lt;em&gt;- oui ce n’est pas du queuing, mais vous avez compris…&lt;/em&gt;). 
Dans ce cas, si votre traitement n’est pas idempotent, vous devrez lutter avec des doublons en base.&lt;/p&gt;

&lt;h3 id=&quot;gestion-des-ressources&quot;&gt;Gestion des ressources&lt;/h3&gt;

&lt;p&gt;Imaginez, vous recevez un fichier de 1Go. 
Vos ressources systèmes sont des PODs avec un 1 Go de RAM.&lt;/p&gt;

&lt;p&gt;Vous voyez le soucis?&lt;/p&gt;

&lt;p&gt;Cet exemple, qui n’est pas trop éloigné de la réalité, mets en évidence l’une des contraintes techniques que vous devrez prendre dès le début de votre conception.&lt;/p&gt;

&lt;p&gt;L’une des solutions serait, par exemple, le traitement quasi systématique du streaming de fichiers et l’obligation d’avoir des fichiers avec des lignes de données indépendantes (c.-à-d. sans avoir à faire de liens inter lignes pendant le traitement).&lt;/p&gt;

&lt;h2 id=&quot;traitement-sur-réception-de-fichiers&quot;&gt;Traitement sur réception de fichiers&lt;/h2&gt;

&lt;p&gt;Dans ce cas, nous avons un processus qui est déclenché lors de la réception d’un fichier. Nous pourrons par exemple avec ce genre d’architecture un fichier qui est envoyé dans espace de stockage objet. Ce dernier est ensuite traité par un programme.
J’ai fait le choix ici de mettre en oeuvre un couplage lâche (on ne se refait pas) entre l’espace de réception de fichiers et le traitement.&lt;/p&gt;

&lt;p&gt;Je traite ici le risque de crash d’un POD en gardant systématiquement les fichiers dans un stockage objet. De cette manière, si le traitement a échoué, un autre POD pourra le télécharger et rejouer le processus batch.&lt;/p&gt;

&lt;p&gt;Ce découplage permet de gérer facilement la scalabilité et les arrêts/relances de PODs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2022/05/batch_evenement-Batch_sur_presence_fichier.svg&quot; alt=&quot;batch_evenement-Batch_sur_presence_fichier&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Dans ce cas, le batch pourra être déployé sous la forme d’un &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&quot;&gt;déploiement Kubernetes&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;traitement-déclenché-à-distance-par-ex-par-un-orchestrateur-de-traitements&quot;&gt;Traitement déclenché à distance (par ex. par un orchestrateur de traitements)&lt;/h2&gt;

&lt;p&gt;Maintenant, on va aborder les traitements qui sont lancés par un ordonnanceur tiers ou tout simplement lancé à distance. 
Généralement, dans le monde de l’entreprise, la planification des traitements est centralisée au lieu de laisser de le faire sur chaque machine avec des &lt;a href=&quot;https://en.wikipedia.org/wiki/Cron&quot;&gt;CRON Jobs&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dans ce cas, on a deux manières de procéder:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Avoir un traitement qui fournit une API permettant de démarrer des traitements et d’avoir leurs statuts.&lt;/li&gt;
  &lt;li&gt;Lancer des jobs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;avec-une-api&quot;&gt;Avec une API&lt;/h3&gt;

&lt;p&gt;Ici, on conçoit les batchs comme des WEBAPPS qui fournissent des traitements batchs sur demande via des APIs. La contrainte est qu’à l’instar de la solution précédente, le programme tourne toujours et n’est vraiment utile que lorsqu’il est appelé via un endpoint REST.&lt;/p&gt;

&lt;p&gt;Ce modèle de conception peut être utilisé à mon avis si la fréquence est forte et si l’intégration d’un Job Kubernetes est problématique pour vous (voir ci-dessous).&lt;/p&gt;

&lt;p&gt;L’un des avantages que l’on pourra trouver est que le &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&quot;&gt;mode de déploiement est assez simple et similaire aux APIs&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2022/05/traitement_api.svg&quot; alt=&quot;traitement_api&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;avec-des-jobs&quot;&gt;Avec des jobs&lt;/h3&gt;

&lt;p&gt;Si votre ordonnanceur peut exécuter le client kubectl, vous pourrez considérer les &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/job/&quot;&gt;jobs  kubernetes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;En résumé, ils permettent de créer un POD et exécute une action en gérant les erreurs potentielles jusqu’à complétion du traitement.&lt;/p&gt;

&lt;p&gt;Par exemple, voici un job permettant de faire un “Hello World!”:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;batch/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Job&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;hello-world&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;helloworld&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;busybox&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;echo&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Hello&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;World!&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;restartPolicy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Never&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;backoffLimit&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Une fois déployé avec Helm, vous pouvez les voir avec la commande &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubectl get jobs&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;minikube kubectl &lt;span class=&quot;nt&quot;&gt;--&lt;/span&gt; get &lt;span class=&quot;nb&quot;&gt;jobs
&lt;/span&gt;NAME          COMPLETIONS   DURATION   AGE
hello-world   0/1           25s        25s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Pour les logs et voir le résultat de la commande lancé, cela se passe d’une manière assez habituelle:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;minikube kubectl &lt;span class=&quot;nt&quot;&gt;--&lt;/span&gt; logs hello-world-zx4wh
Hello World!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;traitement-déclenché-par-cron&quot;&gt;Traitement déclenché par CRON&lt;/h2&gt;

&lt;p&gt;Maintenant, on va laisser le soin au Cluster Kubernetes de lancer les différents traitements via une CRON.
Bien que je ne suis pas trop fan de ne pas centraliser l’ordonnancement, cela peut être très utile si votre plateforme est centrée sur Kubernetes.&lt;/p&gt;

&lt;p&gt;Si vous êtes dans ce cas-là, vous pouvez utiliser l’objet &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/&quot;&gt;CronJob&lt;/a&gt; qui n’est ni plus ni moins qu’un &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/job/&quot;&gt;Job&lt;/a&gt; exécuté de manière périodique.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;batch/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;CronJob&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;hello&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;schedule&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;jobTemplate&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;helloworld-cron&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;busybox&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;echo&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Hello&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;World!&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;restartPolicy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;OnFailure&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;panorama-des-solutions-logicielles-possibles&quot;&gt;Panorama des solutions logicielles possibles&lt;/h2&gt;

&lt;p&gt;Une fois qu’on s’est posé toutes (en tout cas certaines) les questions possibles sur nos exigences techniques et la conception, on peut voir quelles sont les technologies possibles pour implémenter des batchs “cloud natifs”.&lt;/p&gt;

&lt;p&gt;Ça ne sera pas une surprise, je vais m’attarder à la plateforme Java. Il est bien évidemment possible d’utiliser d’autres langages et frameworks tels que Go.&lt;/p&gt;

&lt;p&gt;En Java, vous avez le choix entre différents frameworks :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;[Spring avec spring batch et/ou integration&quot;&gt;Spring avec spring batch&lt;/a&gt; et/ou &lt;a href=&quot;https://spring.io/projects/spring-integration&quot;&gt;integration&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://camel.apache.org/&quot;&gt;Camel&lt;/a&gt; qui peut être utilisé avec &lt;a href=&quot;https://camel.apache.org/manual/spring.html&quot;&gt;Spring&lt;/a&gt; ou &lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt; avec la &lt;a href=&quot;https://github.com/quarkiverse/quarkus-jberet&quot;&gt;JSR 352&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Si vous allez du côté du BigData, vous pouvez aussi envisager d’utiliser des technologies telles qu’&lt;a href=&quot;https://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt;.
Ces dernières vous permettront de &lt;a href=&quot;https://spark.apache.org/docs/latest/running-on-kubernetes.html&quot;&gt;découper “plus facilement” vos traitements&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;le-diable-se-cache-dans-les-détails&quot;&gt;Le diable se cache dans les détails&lt;/h2&gt;

&lt;p&gt;Déployer un batch dans Kubernetes peut se faire assez facilement (en développement) une fois qu’on a compris quelques principes. 
Cependant, les soucis peuvent survenir une fois arrivé en production.&lt;/p&gt;

&lt;p&gt;La gestion des erreurs est beaucoup plus complexe que les APIs. Il vous faudra donc définir avec les différentes parties prenantes quel est le meilleur fonctionnement (rejeu) en production. 
Il vous faudra ainsi bien &lt;a href=&quot;https://blog.touret.info/2022/02/09/analyser-les-risques-pour-mieux-definir-une-architecture/&quot;&gt;identifier et évaluer les risques liés à votre application&lt;/a&gt; et voir quelles sont les actions à mener.&lt;/p&gt;

&lt;p&gt;Aussi, si vous devez manipuler des fichiers volumineux, il faudra faire attention au système de fichiers utilisé et ses performances. Habituellement, avec ce type d’architecture, on utilise généralement du SAN. En fonction de vos exigences, un &lt;a href=&quot;https://www.redhat.com/fr/topics/data-storage/file-block-object-storage&quot;&gt;stockage block&lt;/a&gt; pourra être plus adapté.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Pour conclure cet article, vous aurez compris que le sujet des batchs dans Kubernetes peut s’avérer assez complexe à gérer. 
Au-delà des technologies qui peuvent faire le job (&lt;em&gt;désolé du mauvais jeu de mots&lt;/em&gt;), il vous faudra faire très attention à tout l’environnement dans lequel votre programme devra interagir. Les bases, le réseau, les performances de votre matériel seront des prérequis indispensables.&lt;/p&gt;

&lt;p&gt;Aussi, il vous faudra faire attention à la manière dont sont transmises les données et dont vous les traitez. 
Bref, il faut étudier la solution dans son ensemble du développement à l’exploitation pour s’assurer de ne rien oublier.&lt;/p&gt;

&lt;p&gt;Enfin, cet article n’est bien évidemment pas exhaustif que cela soit sur les solutions ou les contraintes à adresser. 
J’ai néanmoins essayé d’apporter quelques cas concrets et retours d’expérience.&lt;/p&gt;

&lt;p&gt;J’essaierai de détailler un cas concret dans un prochain article.&lt;/p&gt;</content><author><name>Alexandre Touret</name></author><category term="cloud" /><category term="kubernetes" /><category term="batch" /><summary type="html">Quand on parle du Cloud et de Kubernetes, généralement on pense aux APIs. Mais qu’en est-il des batchs?</summary></entry><entry><title type="html">K8S, HELM et Cie: au delà de la hype</title><link href="https://blog.touret.info/2020/10/08/k8s-helm-et-cie-au-dela-de-la-hype/" rel="alternate" type="text/html" title="K8S, HELM et Cie: au delà de la hype" /><published>2020-10-08T08:09:59+00:00</published><updated>2020-10-08T08:09:59+00:00</updated><id>https://blog.touret.info/2020/10/08/k8s-helm-et-cie-au-dela-de-la-hype</id><content type="html" xml:base="https://blog.touret.info/2020/10/08/k8s-helm-et-cie-au-dela-de-la-hype/">&lt;p&gt;Depuis quelques années, &lt;a href=&quot;https://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt; (K8S) et &lt;a href=&quot;https://www.cncf.io/&quot;&gt;son écosystème&lt;/a&gt; deviennent l’environnement d’ exécution à la mode. Certaines personnes veulent déployer sur cet environnement en mettant en avant ses capacités de scalabilité. D’autres font du bashing (souvent) justifié sur la complexité et le coût de mise en œuvre d’une telle plateforme.&lt;br /&gt;
Vous l’aurez compris, cette technologie n’échappe pas &lt;a href=&quot;https://fr.wikipedia.org/wiki/Cycle_du_hype&quot;&gt;au cycle du hype&lt;/a&gt; et à la fameuse courbe du Gartner.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2020/10/gartner_hype_cycle.svg_.png&quot; alt=&quot;cycle hype&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Après quelques expériences sur cette plateforme ( et beaucoup sur d’autres 😀 ) je vais essayer de peser le pour et le contre qui m’apparaissent importants.&lt;br /&gt;
Bien évidemment, ce n’est que mon avis, j’ai sans doute omis certaines informations qui pourraient être indispensables pour d’ autres.&lt;/p&gt;

&lt;h2 id=&quot;pourquoi-et-dans-quelles-conditions-il-ne-faut-pas-utiliser-k8s-&quot;&gt;Pourquoi et dans quelles conditions il ne faut pas utiliser K8S ?&lt;/h2&gt;

&lt;p&gt;Avant de présenter les avantages des applications cloud, je vais essayer de réaliser l’anti thèse de mon propos.&lt;/p&gt;

&lt;h3 id=&quot;en-avez-vous-vraiment-besoin-&quot;&gt;En avez vous (vraiment) besoin ?&lt;/h3&gt;

&lt;p&gt;Vaste sujet et question délicate pour la population informaticienne qui a tendance à suivre les tendances du marché.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2020/10/aaron-blanco-tejedor-vbe9zj-jhbs-unsplash.png&quot; alt=&quot;cycle hype&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Avant de foncer tête baissée dans cette technologie qui est très intéressante au demeurant, il est important de se poser ces quelques questions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Est-ce que mes &lt;a href=&quot;https://fr.wikipedia.org/wiki/Service-level_objectives&quot;&gt;SLO&lt;/a&gt; sont contraignantes?&lt;/li&gt;
  &lt;li&gt;Quel le cycle de déploiement de mes applications?&lt;/li&gt;
  &lt;li&gt;Qui gère les environnements ?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Bref, il faut savoir si le jeu en vaut la chandelle. Si vous avez une application qui doit scaler dynamiquement, encaisser les pics, et avoir du &lt;a href=&quot;https://dzone.com/articles/zero-downtime-deployment&quot;&gt;zero downtime durant les mises à jour&lt;/a&gt;, Kubernetes est fait pour vous. Si vous avez une application de gestion qui n’a pas d’exigences fortes si ce n’est de répondre aux besoins fonctionnels, l’utilisation de Kubernetes est discutable.&lt;/p&gt;

&lt;h3 id=&quot;êtes-vous-taillé-pour-&quot;&gt;Êtes vous taillé pour ?&lt;/h3&gt;

&lt;p&gt;Kubernetes et son écosystème peuvent s’avérer complexes à appréhender. Si votre entreprise opte pour une utilisation « &lt;a href=&quot;https://en.wikipedia.org/wiki/On-premises_software&quot;&gt;on premise&lt;/a&gt;« , c’est pire. Vous devrez avoir une équipe dédiée qui gérera cette plateforme et offrir une expertise aux équipes de développement.&lt;br /&gt;
Ne vous trompez pas. Si votre rôle est de développer des applications métier, il vous sera très difficile d’avoir également une expertise sur l’administration de cette plateforme. Vous pourrez l’utiliser et être à l’aise, mais l’administration d’une telle technologie est très compliquée.&lt;/p&gt;

&lt;p&gt;Le seul conseil que je pourrais vous donner, c’est de ne partir sur Kubernetes que si vous avez une &lt;strong&gt;équipe support à disposition&lt;/strong&gt;. C’est vrai si vous utilisez des services du Cloud tels que Google Cloud ou AWS. Ça l’est encore plus si vous utilisez des services « on premise » tels qu’ Openshift.&lt;/p&gt;

&lt;h3 id=&quot;est-ce-que-vos-développements-sont-cloud-native-&quot;&gt;Est-ce que vos développements sont &lt;a href=&quot;https://www.redhat.com/fr/topics/cloud-native-apps&quot;&gt;« cloud native »&lt;/a&gt; ?&lt;/h3&gt;

&lt;p&gt;Au delà de la plateforme, vous devrez monter en compétence sur le développement et la conception de vos applications.&lt;/p&gt;

&lt;p&gt;Il vous faudra prendre en considération &lt;a href=&quot;https://en.wikipedia.org/wiki/Twelve-Factor_App_methodology&quot;&gt;les 12 facteurs clés&lt;/a&gt; dans vos applications. Il n’est pas forcément la peine de passer sur des microservices. Il est également possible de faire des monolithes modulaires qui peuvent être légers et stateless. Beaucoup de ces facteurs sont communément admis comme des bonnes pratiques de développement logiciel (ex. Il faut une intégration continue).&lt;/p&gt;

&lt;p&gt;Aussi, cela va sans dire, il faut également monter (réellement) en compétence sur les conteneurs et leurs contraintes. Si vous n’avez pas l’habitude de travailler avec des conteneurs ( construction, déploiement, disponibilité d’une &lt;a href=&quot;https://docs.docker.com/registry/&quot;&gt;registry&lt;/a&gt;). Il est préférable de définir une trajectoire avec des étapes intermédiaires.&lt;/p&gt;

&lt;p&gt;Bref, tous ces sujets doivent être adressés et compris pour toutes les parties prenantes de vos équipes que ça soit les développeurs, les chefs de projet et les équipes métiers à une moindre mesure. Cette technologie représente réellement un grand pas à franchir. Si vous ne vous sentez pas de le faire, ou si vous devez gagner en maturité sur ces sujets, attendez avant de vous lancer sur Kubernetes.&lt;/p&gt;

&lt;p&gt;On ne pourra jamais vous reprocher de ne pas opter sur Kubernetes si vous ne remplissez pas tous les pré-requis. Pour ce qui est du contraire…&lt;/p&gt;

&lt;h3 id=&quot;avez-vous-des-interactions-avec-des-services-tiers-qui-sont-compatible-avec-kubernetes-&quot;&gt;Avez vous des interactions avec des services tiers qui sont compatible avec Kubernetes ?&lt;/h3&gt;

&lt;p&gt;Quand vous restez dans votre cluster Kubernetes, généralement, tout va bien. Dès que vous avez des interactions avec des services tiers, ça peut se compliquer.&lt;br /&gt;
En effet, généralement vous devrez vous connecter à des services tiers qui ne sont pas orienté cloud : &lt;a href=&quot;https://en.wikipedia.org/wiki/Hardware_security_module&quot;&gt;des boitiers crypto&lt;/a&gt;, des passerelles de transfert, …&lt;br /&gt;
Il se peut que certains protocoles soient également incompatibles avec Kubernetes. Il vous faudra vous assurer que tout la galaxie de logiciels et systèmes gravitant autour de votre application sera compatible avec une telle architecture. Ceci n’est pas une mince affaire. L’aide d’une équipe support (voir ci-dessus) vous sera d’une grande utilité.&lt;/p&gt;

&lt;h2 id=&quot;pourquoi-sauter-le-pas-&quot;&gt;Pourquoi sauter le pas ?&lt;/h2&gt;

&lt;h3 id=&quot;la-scalabilité-et-la-résistance-à-la-panne&quot;&gt;La scalabilité et la résistance à la panne&lt;/h3&gt;

&lt;p&gt;Personnellement, la première fonctionnalité qui m’a intéressé c’est la gestion de la scalabilité. Si vous avez des objectifs de 99.9% de disponibilité. Kubernetes sera une plus value indéniable dans votre architecture. Après quelques &lt;s&gt;jours&lt;/s&gt; heures à batailler avec les fichiers YAML, vous pourrez gérer automatiquement la scalabilité en fonction de plusieurs indicateurs qu’ils soient techniques (ce sont les plus faciles à gérer) ou un peu plus métier &lt;a href=&quot;https://www.metricfire.com/blog/prometheus-metrics-based-autoscaling-in-kubernetes/&quot;&gt;en utilisant Prometheus&lt;/a&gt; – et oui encore une technologie supplémentaire à connaître.&lt;/p&gt;

&lt;p&gt;En effet, au lieu de vous en soucier une fois arrivé en production, vous aurez lors du développement l’obligation de prendre en considération l’observabilité de votre application. Par exemple, vous aurez à renseigner &lt;a href=&quot;https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/&quot;&gt;si votre application est prête et/ou disponible pour traiter les requêtes&lt;/a&gt;. Ces indicateurs vous permettront de scaler &lt;strong&gt;automatiquement&lt;/strong&gt; et de re-créer si nécessaire un &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/pods/&quot;&gt;POD&lt;/a&gt; en cas de panne.&lt;/p&gt;

&lt;p&gt;J’ai trouvé que cette pratique était vertueuse. Bien évidemment, pas besoin d’être sur Kubernetes pour avoir de l’observabilité dans des applications. Par contre, ici, c’est obligatoire et implémenté dès le développement.&lt;/p&gt;

&lt;p&gt;La scalabilité automatique est aussi très intéressante. On a souvent vu des serveurs en production qui n’étaient pas suffisamment utilisés. Ici vous n’aurez que les instances nécessaires pour votre cas d’utilisation.&lt;br /&gt;
La contrainte que l’on peut voir à cette fonctionnalité et qu’on ne maitrise pas complètement le nombre d’instances disponibles. C’est Kubernetes qui s’en charge en prenant en compte le paramétrage que vous aurez renseigné dans vos &lt;a href=&quot;https://helm.sh/docs/chart_best_practices/templates/&quot;&gt;templates HELM&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;le-déploiement&quot;&gt;Le déploiement&lt;/h3&gt;

&lt;p&gt;Avant de déployer (dans la vraie vie), vous aurez à mettre en place un pipeline CI/CD qui orchestre les différents déploiements sur tous vos environnements. Attention, ce n’est pas une mince affaire 🙂 !&lt;/p&gt;

&lt;p&gt;Une fois réalisé, vous verrez automatiquement le gain. Vos déploiements seront réellement fluides. Bon OK, on peut le faire sur des &lt;a href=&quot;https://en.wikipedia.org/wiki/Virtual_machine&quot;&gt;VMS&lt;/a&gt; standards. Mais on peut améliorer la procédure de déploiement pour mettre en place du &lt;a href=&quot;https://dzone.com/articles/zero-downtime-deployment&quot;&gt;zero downtime&lt;/a&gt; pour ne pas interrompre le service lors d’un déploiement.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;strategy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;RollingUpdate&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;rollingUpdate&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;maxSurge&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;maxUnavailable&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;linfrastructure-as-code&quot;&gt;L’Infrastructure As Code&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2020/10/jacek-dylag-nhcpop4a2xo-unsplash.png&quot; alt=&quot;iaac&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Quand on pense à Kubernetes, et au cloud, on ne pense pas trop à l’&lt;a href=&quot;https://en.wikipedia.org/wiki/Infrastructure_as_code&quot;&gt;Infrastructure As Code&lt;/a&gt; au début. Cependant, cette pratique est pour moi l’une des plus utiles.&lt;/p&gt;

&lt;p&gt;En effet, avoir votre système décrit dans des fichiers, versionnés vous permet de le tester dès le développement. Ça évite ( dans la majorité des cas ) les erreurs lors des installations d’environnement. La mise à jour des logiciels est largement accélérée.&lt;/p&gt;

&lt;p&gt;Bien évidemment, il existe &lt;a href=&quot;https://www.terraform.io/&quot;&gt;Terraform&lt;/a&gt; et &lt;a href=&quot;https://www.ansible.com/&quot;&gt;Ansible&lt;/a&gt; pour le provisionning des environnements. Ici je trouve qu’on pousse le concept encore plus loin. L’automatisation est à mon avis poussé à paroxysme.&lt;br /&gt;
Prenons par exemple la gestion des systèmes d’exploitation. La mise à jour sur des serveurs physiques ou virtuels peut prendre énormément de temps et générer des erreurs. Avec de l’infra as code, ceci est testé et validé automatiquement via des tests unitaires dès l’environnement de développement.&lt;br /&gt;
On peut suivre la gestion des environnements via un gestionnaire de sources et la promotion vers les autres environnements (recette[1-n], pré-production, production) est grandement accélérée.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Bon, vous l’aurez peut être compris, cette galaxie de technologies est intéressante et peut vous aider dans vos projets. Avant d’arriver à l’utiliser sereinement, il vous faudra sans doute définir une trajectoire et appréhender plusieurs sujets avant d’arriver à déployer vos applications sur un cloud interne ou externe.&lt;br /&gt;
J’espère que cet article vous aura permis de mettre en évidence les pour et contre d’une telle technologie et le cas échéant vous donnera envie de franchir le pas.&lt;/p&gt;</content><author><name>Alexandre Touret</name></author><category term="helm" /><category term="hype" /><category term="k8s" /><category term="kubernetes" /><summary type="html">Depuis quelques années, Kubernetes (K8S) et son écosystème deviennent l’environnement d’ exécution à la mode. Certaines personnes veulent déployer sur cet environnement en mettant en avant ses capacités de scalabilité. D’autres font du bashing (souvent) justifié sur la complexité et le coût de mise en œuvre d’une telle plateforme. Vous l’aurez compris, cette technologie n’échappe pas au cycle du hype et à la fameuse courbe du Gartner.</summary></entry><entry><title type="html">Utiliser des GITHUB Actions pour déployer dans Google Kubernetes Engine</title><link href="https://blog.touret.info/2020/05/10/utiliser-des-github-actions-pour-deployer-dans-google-kubernetes-engine/" rel="alternate" type="text/html" title="Utiliser des GITHUB Actions pour déployer dans Google Kubernetes Engine" /><published>2020-05-10T06:22:00+00:00</published><updated>2020-05-10T06:22:00+00:00</updated><id>https://blog.touret.info/2020/05/10/utiliser-des-github-actions-pour-deployer-dans-google-kubernetes-engine</id><content type="html" xml:base="https://blog.touret.info/2020/05/10/utiliser-des-github-actions-pour-deployer-dans-google-kubernetes-engine/">&lt;p&gt;A mes heures perdues, je travaille sur un « POC/side project qui n’aboutira pas et je m’en fiche » basé sur Quarkus. J’ ai choisi d’utiliser les langages et composants suivants :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://kotlinlang.org/&quot;&gt;Kotlin&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://gradle.org/&quot;&gt;Gradle&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt; pour le déploiement&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Oui, tant qu’à faire, autant aller dans la hype …&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2020/05/article_github_actions_k8s-1.png&quot; alt=&quot;boot&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/alexandre-touret/music-quote&quot;&gt;Mon projet est sur GITHUB&lt;/a&gt;. Pour automatiser certaines actions et, disons-le, par fierté personnelle, j’ai choisi d’automatiser certaines actions par la mise en œuvre de pipelines CI/CD.&lt;br /&gt;
Depuis peu, GITHUB a intégré un mécanisme de pipeline : &lt;a href=&quot;https://github.com/features/actions&quot;&gt;GITHUB Actions&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Ça permet, entre autres, de lancer des processus automatisé sur un push ou sur une action pour un commit GIT.&lt;/p&gt;

&lt;p&gt;La force de l’outil est, selon moi, de facilement s’intégrer avec beaucoup de services du cloud ( sonarcloud, google cloud, heroku,…). On aime ou on n’aime pas, mais chez Microsoft, l’intégration ils savent faire.&lt;/p&gt;

&lt;p&gt;Par exemple, si on veut lancer une compilation lors d’un push, on peut placer un fichier &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.github/workflows/build.xml&lt;/code&gt; avec le contenu :&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;CI&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;jobs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;runs-on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ubuntu-latest&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;actions/checkout@v1&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Set up JDK &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;actions/setup-java@v1&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;java-version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Build with Gradle without testing&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;./gradlew build -x test&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Coté GITHUB, vous verrez l’exécution sur un écran dédié&lt;figure class=&quot;wp-block-image size-large is-resized&quot;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2020/05/screenshot_2020-05-08-alexandre-touret-music-quote.png&quot; alt=&quot;boot&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Vous pouvez créer autant de workflows que vous souhaitez (si votre projet est en libre accès).&lt;br /&gt;
Pour chaque workflow, on peut définir et utiliser des jobs. Les logs d’exécution sont disponibles dans ce même écran:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2020/05/screenshot_2020-05-09-alexandre-touret-music-quote.png&quot; alt=&quot;workflow&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;worflows-implémentés&quot;&gt;Worflows implémentés&lt;/h2&gt;

&lt;p&gt;J’ai choisi d’implémenter les workflows suivants:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;CI&lt;/strong&gt;: Build sur la feature branch&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;CD&lt;/strong&gt;: Build sur master branch et déploiement&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On obtient donc dans mon cas:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2020/05/workflow.png&quot; alt=&quot;workflow&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ce n’est pas parfait. Loin de là. Dans la « vraie vie », pour une équipe de dev, je l’améliorerai sans doute par un build docker dans les features branches, une validation formelle et bloquante de l’analyse sonar, etc.&lt;br /&gt;
Pour un dev perso ça suffit largement. Le contenu de la branche master est compilé et une image docker est crée pour être déployée automatiquement dans GKE.&lt;/p&gt;

&lt;h2 id=&quot;analyse-sonar&quot;&gt;Analyse SONAR&lt;/h2&gt;

&lt;p&gt;J’ai choisi d’utiliser &lt;a href=&quot;http://sonarcloud.io/&quot;&gt;sonarcloud&lt;/a&gt; pour analyser mon code. C’est gratuit pour les projets opensource. L’analyse se fait simplement:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;sonarCloudTrigger&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;SonarCloud Trigger&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;runs-on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ubuntu-latest&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;actions/checkout@v1&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Set up JDK &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;actions/setup-java@v1&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;java-version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;SonarCloud Scan&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;GITHUB_TOKEN&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;SONAR_TOKEN&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;./gradlew jacocoTestReport sonarqube&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Dans ce job j’utilise deux &lt;a href=&quot;https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets&quot;&gt;secrets&lt;/a&gt;. Ce sont des tokens qui permettent de ne pas stocker en dur les données dans les repos GITHUB.&lt;/p&gt;

&lt;h2 id=&quot;création-dune-image-docker-et-déploiement-dans-le-registry-github&quot;&gt;Création d’une image Docker et déploiement dans le registry GITHUB&lt;/h2&gt;

&lt;p&gt;Ici aussi, ça se fait simplement. La preuve :&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;jobs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;runs-on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ubuntu-latest&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;actions/checkout@v1&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Set up JDK &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;actions/setup-java@v1&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;java-version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Build in JVM Mode with Gradle without testing&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;./gradlew quarkusBuild  [1]&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Branch name&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;echo running on branch ${GITHUB_REF##*/}&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Build the Docker image Quarkus JVM&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;docker build -f src/main/docker/Dockerfile.jvm -t docker.pkg.github.com/${GITHUB_REPOSITORY}/music-quote-jvm:latest .  [2]&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Login against github docker repository&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;GITHUB_TOKEN&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;docker login -u ${GITHUB_ACTOR} -p ${GITHUB_TOKEN}  docker.pkg.github.com   [3]&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Publish the Docker image Quarkus JVM&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;docker push docker.pkg.github.com/${GITHUB_REPOSITORY}/music-quote-jvm:latest  [4]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;Création du binaire&lt;/li&gt;
  &lt;li&gt;Création de l’image docker en utilisant la commande docker et le Dockerfile fourni par Quarkus&lt;/li&gt;
  &lt;li&gt;Identification sur la registry Docker de GITHUB&lt;/li&gt;
  &lt;li&gt;Déploiement de l’image&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Pour plus de détails sur la variable GITHUB_TOKEN, vous pouvez lire &lt;a href=&quot;https://help.github.com/en/actions/configuring-and-managing-workflows/authenticating-with-the-github_token&quot;&gt;cet article de la documentation&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;déploiement-dans-google-kubernetes-engine&quot;&gt;Déploiement dans Google Kubernetes Engine&lt;/h2&gt;

&lt;p&gt;Mon application est pour l’instant architecturée comme suit (&lt;em&gt;attention c’est compliqué&lt;/em&gt;):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2020/05/application-1.png&quot; alt=&quot;workflow&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Pour la déployer dans Google Kubernetes Engine, j’ai besoin d’ implémenter cette « architecture » par les objets Kubernetes suivants:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2020/05/application_gke.png&quot; alt=&quot;workflow&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;J’utilise les objets suivants:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Des services pour exposer la base de données ainsi que l’application&lt;/li&gt;
  &lt;li&gt;Un deployment pour l’application&lt;/li&gt;
  &lt;li&gt;Des pods car à un moment, il en faut…&lt;/li&gt;
  &lt;li&gt;Un statefulset pour la base de données&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Vous pourrez trouver la définition de tous ces objets au format yaml via &lt;a href=&quot;https://github.com/alexandre-touret/music-quote/tree/master/k8s&quot;&gt;ce lien&lt;/a&gt;. J’ai fait très simple. Logiquement j’aurai du créer un volume pour les bases de données ou utiliser une base de données en mode PAAS.&lt;/p&gt;

&lt;p&gt;Pour lancer le déploiement, il faut au préalable créer un secret ( fait manuellement pour ne pas stocker d’objet yaml dans le repository GITHUB) pour se connecter au repo GITHUB via la commande suivante:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create secret docker-registry github-registry &lt;span class=&quot;nt&quot;&gt;--docker-server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;docker.pkg.github.com &lt;span class=&quot;nt&quot;&gt;--docker-username&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;USER--docker-password&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;PASSWORD &lt;span class=&quot;nt&quot;&gt;--docker-email&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;EMAIL
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;On peut faire pareil pour les connexions base de données. J’ai mis dans un configmap pour ne pas trop me prendre la tête…&lt;/p&gt;

&lt;p&gt;Après le déploiement via le pipeline se fait assez simplement:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;GoogleCloudPlatform/github-actions/setup-gcloud@master&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;286.0.0'&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;service_account_email&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;service_account_key&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;project_id&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;# Get the GKE credentials so we can deploy to the cluster&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|-&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;gcloud container clusters get-credentials &quot;$&quot; --zone &quot;$&quot;&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;# Deploy the Docker image to the GKE cluster&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Deploy&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|-&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;kubectl apply -f ./k8s     &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;J’utilise &lt;a href=&quot;https://github.com/GoogleCloudPlatform/github-actions&quot;&gt;les « actions » fournies par Google&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Pour que ça marche il y a pas mal d’étapes préalables ( des tokens à générer, un utilisateur technique, …).&lt;br /&gt;
J’ai essayé de les référencer dans &lt;a href=&quot;https://github.com/alexandre-touret/music-quote&quot;&gt;le README du projet&lt;/a&gt;.&lt;br /&gt;
Si vous voulez tester l’intégration Kubernetes dans le cloud google, sachez que vous pouvez disposer d’un crédit de 300€ valable un an. Attention, avec ce genre d’architecture, ça part vite…&lt;/p&gt;</content><author><name>Alexandre Touret</name></author><category term="github" /><category term="gradle" /><category term="kubernetes" /><summary type="html">A mes heures perdues, je travaille sur un « POC/side project qui n’aboutira pas et je m’en fiche » basé sur Quarkus. J’ ai choisi d’utiliser les langages et composants suivants :</summary></entry></feed>