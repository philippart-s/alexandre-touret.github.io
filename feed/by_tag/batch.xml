<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="https://blog.touret.info/feed/by_tag/batch.xml" rel="self" type="application/atom+xml" /><link href="https://blog.touret.info/" rel="alternate" type="text/html" /><updated>2022-08-16T10:17:53+00:00</updated><id>https://blog.touret.info/feed/by_tag/batch.xml</id><title type="html">blog.touret.info</title><subtitle>Mon blog personnel. J'y expose mes derniers travaux et ma veille technologique. Au menu en vrac: Java, Kotlin, Maven, Docker, Cloud, Kubernetes, logiciels libres, Debian, Ubuntu, Gnu/Linux, des talks online et présentiels.</subtitle><author><name>Alexandre Touret</name></author><entry><title type="html">Déployer des batchs cloud native avec Spring Cloud Data Flow</title><link href="https://blog.touret.info/2022/08/16/spring-data-flow/" rel="alternate" type="text/html" title="Déployer des batchs cloud native avec Spring Cloud Data Flow" /><published>2022-08-16T08:00:00+00:00</published><updated>2022-08-16T08:00:00+00:00</updated><id>https://blog.touret.info/2022/08/16/spring-data-flow</id><content type="html" xml:base="https://blog.touret.info/2022/08/16/spring-data-flow/">&lt;p&gt;&lt;a href=&quot;https://blog.touret.info/2022/05/17/cloud-native-batchs/&quot;&gt;Dans mon dernier article&lt;/a&gt;, j’ai tenté de faire un état des lieux des solutions possibles pour implémenter des batchs cloud natifs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2022/08/maksym-tymchyk-vHO-yT1BDWk-unsplash.webp&quot; alt=&quot;flow&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;J’ai par la suite testé plus en détails les &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/job/&quot;&gt;jobs&lt;/a&gt; et &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/&quot;&gt;cron jobs&lt;/a&gt; Kubernetes en essayant d’avoir une vue OPS sur ce sujet.
Le principal inconvénient (qui ne l’est pas dans certains cas) des jobs est qu’on ne peut pas les rejouer.
Si ces derniers sont terminés avec succès - &lt;em&gt;Vous allez me dire, il faut bien les coder&lt;/em&gt; - mais qu’on souhaite les rejouer pour diverses raisons, on doit les supprimer et relancer.
J’ai vu plusieurs posts sur StackOverflow à ce sujet, je n’ai pas trouvé de solutions satisfaisantes relatifs à ce sujet.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2022/08/luke_cage.webp&quot; alt=&quot;luke_cage&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Attention, je ne dis pas que les jobs et cron jobs ne doivent pas être utilisés.
Loin de là.&lt;/p&gt;

&lt;p&gt;Je pense que si vous avez besoin d’un traitement sans chaînage d’actions, sans rejeu, les &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/job/&quot;&gt;jobs&lt;/a&gt; et &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/&quot;&gt;cron jobs&lt;/a&gt; sont de bonnes options.
Le monitoring et reporting des actions réalisées peut se faire par l’observabilité mise en place dans votre cluster K8S.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2022/08/spring_dataflow_logo.webp&quot; alt=&quot;spring dataflow logo&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Après plusieurs recherches, je suis tombé sur &lt;a href=&quot;https://dataflow.spring.io/&quot;&gt;Spring Data Flow&lt;/a&gt;. 
L’offre de ce module de &lt;a href=&quot;https://spring.io/projects/spring-cloud&quot;&gt;Spring Cloud&lt;/a&gt; va au delà des batchs. 
Il permet notamment de gérer le streaming via une interface graphique ou via son &lt;a href=&quot;https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#api-guide&quot;&gt;API&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dans cet article, je vais implémenter un exemple et le déployer dans &lt;a href=&quot;https://minikube.sigs.k8s.io/&quot;&gt;Minikube&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;installation-et-configuration-de-minikube&quot;&gt;Installation et configuration de Minikube&lt;/h2&gt;

&lt;p&gt;L’installation de minikube est décrite sur &lt;a href=&quot;https://minikube.sigs.k8s.io/docs/start/&quot;&gt;le site officiel&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Pour l’installer, j’ai exécuté les commandes suivantes:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl &lt;span class=&quot;nt&quot;&gt;-LO&lt;/span&gt; https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
&lt;span class=&quot;nb&quot;&gt;sudo install &lt;/span&gt;minikube-linux-amd64 /usr/local/bin/minikube
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Au premier démarrage, vous finirez l’installation&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;minikube start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;installation-de-spring-cloud-data-flow&quot;&gt;Installation de Spring Cloud Data Flow&lt;/h3&gt;

&lt;p&gt;Pour installer Spring Cloud Data Flow directement dans Kubernetes, vous pouvez exécuter les commandes suivantes:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;helm repo add bitnami https://charts.bitnami.com/bitnami
helm &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;my-release bitnami/spring-cloud-dataflow
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Après quelques minutes de téléchargement, vous devriez avoir le retour suivante à l’exécution de la commande &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubectl get pods&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pods

~ » kubectl get pods                                                                           
NAME  READY   STATUS             RESTARTS      AGE
dataflow-mariadb-0  1/1     Running            1 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;24h ago&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   24h
dataflow-rabbitmq-0 1/1     Running            1 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;24h ago&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   24h
dataflow-spring-cloud-dataflow-server-75db59d6cb-lrwp8   1/1 Running            1 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;24h ago&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   24h
dataflow-spring-cloud-dataflow-skipper-9db568cf4-rzsqq   1/1     Running            1 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;24h ago&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   24h
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;accès-au-dashboard&quot;&gt;Accès au dashboard&lt;/h3&gt;

&lt;p&gt;Pour accéder au &lt;a href=&quot;https://cloud.spring.io/spring-cloud-dataflow-ui/&quot;&gt;dashboard de Spring Cloud Data Flow&lt;/a&gt;, vous pouvez lancer les commandes suivantes:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SERVICE_PORT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;kubectl get &lt;span class=&quot;nt&quot;&gt;--namespace&lt;/span&gt; default &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;jsonpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{.spec.ports[0].port}&quot;&lt;/span&gt; services dataflow-spring-cloud-dataflow-server&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
kubectl port-forward &lt;span class=&quot;nt&quot;&gt;--namespace&lt;/span&gt; default svc/dataflow-spring-cloud-dataflow-server &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SERVICE_PORT&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SERVICE_PORT&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Ensuite, vous pourrez accéder à la console web via l’URL &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://localhost:8080/dashboard&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;développement-dune-task&quot;&gt;Développement d’une Task&lt;/h2&gt;

&lt;p&gt;J’ai crée une simple task qui va rechercher la nationalité d’un prénom. 
Pour ceci, j’utilise l’API &lt;a href=&quot;https://api.nationalize.io/&quot;&gt;https://api.nationalize.io/&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;On passe un prénom en paramètre et on obtient une liste de nationalités possibles avec leurs probabilités.&lt;/p&gt;

&lt;p&gt;Vous trouverez les sources de cet exemple sur &lt;a href=&quot;https://github.com/alexandre-touret/cloud-task&quot;&gt;mon Github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Aussi, &lt;a href=&quot;https://dataflow.spring.io/docs/batch-developer-guides/batch/spring-task/&quot;&gt;la documentation est bien faite, il suffit de la lire&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;initialisation&quot;&gt;Initialisation&lt;/h3&gt;

&lt;p&gt;J’ai initié un projet Spring avec les dépendances suivantes:&lt;/p&gt;

&lt;div class=&quot;language-groovy highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;dependencies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;implementation&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'org.springframework.boot:spring-boot-starter-web'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;implementation&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'org.springframework.cloud:spring-cloud-starter-task'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;developmentOnly&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'org.springframework.boot:spring-boot-devtools'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;testImplementation&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'org.springframework.boot:spring-boot-starter-test'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;implementation&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'org.springframework.boot:spring-boot-starter-jdbc'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;runtimeOnly&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'org.mariadb.jdbc:mariadb-java-client'&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dependencyManagement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;imports&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mavenBom&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;org.springframework.cloud:spring-cloud-dependencies:${springCloudVersion}&quot;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Attention, les starters et dépendances JDBC/MariaDB sont indispensables pour que votre tâche puisse enregistrer le statut des exécutions.&lt;/p&gt;

&lt;h3 id=&quot;construction-de-la-tâche&quot;&gt;Construction de la tâche&lt;/h3&gt;

&lt;p&gt;Une tâche se crée facilement en annotation une classe “Configuration” par l’annotation &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@EnableTask&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nd&quot;&gt;@Configuration&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@EnableTask&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TaskConfiguration&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Ensuite l’essentiel du job s’effectue dans la construction d’un bean &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CommandLineRunner&lt;/code&gt; :&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;nd&quot;&gt;@Bean&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CommandLineRunner&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;createCommandLineRunner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;RestTemplate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;restTemplate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;commandLinePropertySource&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleCommandLinePropertySource&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;restTemplate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getForEntity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://api.nationalize.io/?name=&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ofNullable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;commandLinePropertySource&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getProperty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;orElse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BLANK&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NationalizeResponseDTO&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;no&quot;&gt;LOGGER&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;RESPONSE[{}]: {}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getStatusCode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getBody&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;};&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Dans mon exemple, j’affiche dans la sortie standard le payload de l’API ainsi que le code HTTP de la réponse.&lt;/p&gt;

&lt;p&gt;Voici un exemple d’exécution :&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2022-08-12 15:11:07.885  INFO 1 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;s&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: 8080 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;http&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; with context path &lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;
2022-08-12 15:11:07.894  INFO 1 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;           main] i.t.b.cloudtask.CloudTaskApplication     : Started CloudTaskApplication &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;17.704 seconds &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;JVM running &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;19.18&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
2022-08-12 15:11:10.722  INFO 1 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;           main] i.t.batch.cloudtask.TaskConfiguration    : RESPONSE[200 OK]: NationalizeResponseDTO&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Alexandre'&lt;/span&gt;, &lt;span class=&quot;nv&quot;&gt;countries&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=[&lt;/span&gt;CountryDTO&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;countryId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'BR'&lt;/span&gt;, pr....
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;packaging&quot;&gt;Packaging&lt;/h3&gt;

&lt;p&gt;Ici rien de nouveau, il suffit de lancer la commande:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./gradlew build
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;déploiement&quot;&gt;Déploiement&lt;/h2&gt;

&lt;h3 id=&quot;création-et-déploiement-de-limage-docker&quot;&gt;Création et déploiement de l’image Docker&lt;/h3&gt;
&lt;p&gt;Pour déployer notre toute nouvelle tâche, nous allons d’abord créer l’image Docker avec buildpack.&lt;/p&gt;

&lt;p&gt;Tout d’abord on va se brancher sur minikube pour que notre image soit déployée dans le repository de minikube&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;minikube docker-env&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Ensuite, il nous reste à créer l’image Docker&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./gradlew bootBuildImage &lt;span class=&quot;nt&quot;&gt;--imageName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;info.touret/cloud-task:latest
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Pour vérifier que votre image est bien présente dans minikube, vous pouvez exécuter la commande suivante:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;minikube image &lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;cloud-task                                                                                                                                                                          
info.touret/cloud-task:latest
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;création-de-lapplication&quot;&gt;Création de l’application&lt;/h3&gt;

&lt;p&gt;Avant de créer la tâche dans l’interface, il faut d’abord référencer l’image Docker en créer une &lt;a href=&quot;https://dataflow.spring.io/docs/applications/&quot;&gt;application&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2022/08/dataflow_config5.webp&quot; alt=&quot;application&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Il faut déclarer l’image Docker avec le formalisme présenté dans la capture d’écran.&lt;/p&gt;

&lt;h3 id=&quot;création-de-la-tâche&quot;&gt;Création de la tâche&lt;/h3&gt;

&lt;p&gt;Voici les différentes actions que j’ai réalisé via l’interface:&lt;/p&gt;

&lt;figure class=&quot;half &quot;&gt;
  
    
      &lt;a href=&quot;/assets/images/2022/08/dataflow_config3.webp&quot;&gt;
          &lt;img src=&quot;/assets/images/2022/08/dataflow_config3.webp&quot; alt=&quot;init&quot; /&gt;
      &lt;/a&gt;
    
  
    
      &lt;a href=&quot;/assets/images/2022/08/dataflow_config4.webp&quot;&gt;
          &lt;img src=&quot;/assets/images/2022/08/dataflow_config4.webp&quot; alt=&quot;init&quot; /&gt;
      &lt;/a&gt;
    
  
  
    &lt;figcaption&gt;Création de la tâche
&lt;/figcaption&gt;
  
&lt;/figure&gt;

&lt;p&gt;Vous trouverez plus de détails dans &lt;a href=&quot;https://dataflow.spring.io/docs/batch-developer-guides/batch/data-flow-simple-task/&quot;&gt;la documentation officielle&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;exécution&quot;&gt;Exécution&lt;/h2&gt;

&lt;p&gt;Maintenant, il nous est possible de lancer notre tâche.
Vous trouverez dans les copies d’écran ci-dessous les différentes actions que j’ai réalisé pour exécuter ma toute nouvelle tâche.&lt;/p&gt;

&lt;figure class=&quot;half &quot;&gt;
  
    
      &lt;a href=&quot;/assets/images/2022/08/dataflow_config2.webp&quot;&gt;
          &lt;img src=&quot;/assets/images/2022/08/dataflow_config2.webp&quot; alt=&quot;create&quot; /&gt;
      &lt;/a&gt;
    
  
    
      &lt;a href=&quot;/assets/images/2022/08/dataflow_config10.webp&quot;&gt;
          &lt;img src=&quot;/assets/images/2022/08/dataflow_config10.webp&quot; alt=&quot;init&quot; /&gt;
      &lt;/a&gt;
    
  
    
      &lt;a href=&quot;/assets/images/2022/08/dataflow_config8.webp&quot;&gt;
          &lt;img src=&quot;/assets/images/2022/08/dataflow_config8.webp&quot; alt=&quot;init&quot; /&gt;
      &lt;/a&gt;
    
  
    
      &lt;a href=&quot;/assets/images/2022/08/dataflow_config7.webp&quot;&gt;
          &lt;img src=&quot;/assets/images/2022/08/dataflow_config7.webp&quot; alt=&quot;init&quot; /&gt;
      &lt;/a&gt;
    
  
    
      &lt;a href=&quot;/assets/images/2022/08/dataflow_config9.webp&quot;&gt;
          &lt;img src=&quot;/assets/images/2022/08/dataflow_config9.webp&quot; alt=&quot;init&quot; /&gt;
      &lt;/a&gt;
    
  
  
    &lt;figcaption&gt;Exécution de la tâche
&lt;/figcaption&gt;
  
&lt;/figure&gt;

&lt;p&gt;J’ai pu également accéder aux logs.&lt;/p&gt;

&lt;p&gt;Il est également important de noter qu’ après l’exécution d’une tâche, le POD est toujours au statut &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RUNNING&lt;/code&gt;  afin que Kubernetes ne redémarre pas automatiquement le traitement.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pods | &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;cloud-task                                                                                                                                                                           
cloud-task-7mp72gzpwo                                    1/1     Running            0               57m
cloud-task-pymdkr182p                                    1/1     Running            0               65m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A chaque exécution il y aura donc un pod d’alloué.&lt;/p&gt;

&lt;h2 id=&quot;aller-plus-loin&quot;&gt;Aller plus loin&lt;/h2&gt;

&lt;p&gt;Parmi les fonctionnalités que j’ai découvert, on peut :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;relancer un traitement&lt;/li&gt;
  &lt;li&gt;le programmer&lt;/li&gt;
  &lt;li&gt;nettoyer les exécutions&lt;/li&gt;
  &lt;li&gt;les pistes d’audit&lt;/li&gt;
  &lt;li&gt;le chaînage des différentes tâches&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Gros inconvénient pour le nettoyage: e n’ai pas constaté un impact dans les pods alloués.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Pour résumer, je vais me risquer à comparer les deux solutions jobs/cron jobs Kubernetes et une solution basée sur Spring Cloud Dataflow.
Je vais donc utiliser la liste des caractéristiques présentée par &lt;a href=&quot;https://fundamentalsofsoftwarearchitecture.com/&quot;&gt;M. Richards et N. Ford dans leur livre: Fundamentals of Software Architecture&lt;/a&gt;&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Bien évidemment, cette notation est purement personnelle.
Vous noterez que selon où on positionne le curseur, l’une des deux solutions peut s’avérer meilleure (ou pas).&lt;/p&gt;

&lt;p&gt;Bref, tout dépend de vos contraintes et de ce que vous souhaitez en faire.
A mon avis, une solution telle que Spring Cloud Dataflow s’inscrit parfaitement pour des traitements mixtes (streaming, batch) et pour des traitements Big Data.&lt;/p&gt;

&lt;p&gt;N’hésitez pas à me donner votre avis (&lt;a href=&quot;https://blog.touret.info/a-propos/&quot;&gt;sans troller svp&lt;/a&gt;) en commentaire ou si ça concerne &lt;a href=&quot;https://github.com/alexandre-touret/cloud-task&quot;&gt;l’exemple, directement dans Github&lt;/a&gt;.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Architecture characteristic&lt;/th&gt;
      &lt;th&gt;K8s job rating&lt;/th&gt;
      &lt;th&gt;Spring Cloud Dataflow rating&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Partitioning type&lt;/td&gt;
      &lt;td&gt;Domain &amp;amp; technical&lt;/td&gt;
      &lt;td&gt;Domain &amp;amp; technical&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of quanta &lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1 to many&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Deployability&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Elasticity&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Evolutionary&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fault Tolerance&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Modularity&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Overall cost&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Performance&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Reliability&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Scalability&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Simplicity&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Testability&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐&lt;/td&gt;
      &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;A lire absolument! &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;~ Nombre de livrables indépendants fortement couplés &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Alexandre Touret</name></author><category term="cloud" /><category term="kubernetes" /><category term="batch" /><category term="spring" /><summary type="html">Dans mon dernier article, j’ai tenté de faire un état des lieux des solutions possibles pour implémenter des batchs cloud natifs.</summary></entry><entry><title type="html">Faire des batchs “Cloud Native” dans Kubernetes</title><link href="https://blog.touret.info/2022/05/17/cloud-native-batchs/" rel="alternate" type="text/html" title="Faire des batchs “Cloud Native” dans Kubernetes" /><published>2022-05-17T08:00:00+00:00</published><updated>2022-05-17T08:00:00+00:00</updated><id>https://blog.touret.info/2022/05/17/cloud-native-batchs</id><content type="html" xml:base="https://blog.touret.info/2022/05/17/cloud-native-batchs/">&lt;p&gt;Quand on parle du Cloud et de Kubernetes, généralement on pense aux APIs.
Mais qu’en est-il des batchs?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2022/05/pat-whelen-xSsWBa4rb6E-unsplash.webp&quot; alt=&quot;pat-whelen-xSsWBa4rb6E-unsplash.jpg &quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Oui, depuis plusieurs années, on pensait les éradiquer, mais ils sont encore là et on en a encore besoin pour quelques années encore. 
Ils ont même eu une deuxième jeunesse avec le Big Data et l’explosion des volumétries dans l’IT.&lt;/p&gt;

&lt;p&gt;Je vais essayer de faire un tour d’horizon dans cet article des batchs dans un environnement Cloud et plus particulièrement dans Kubernetes.&lt;/p&gt;

&lt;p&gt;Les exemples présentés dans cet article seront (sans doute) approfondis dans un second article et d’ores et déjà disponibles dans &lt;a href=&quot;https://github.com/alexandre-touret/k8s-batch&quot;&gt;mon GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;pourquoi-des-batchs-dans-le-cloud&quot;&gt;Pourquoi des batchs dans le Cloud?&lt;/h2&gt;

&lt;p&gt;A ce titre un peu provocateur, j’ajouterais aussi &lt;em&gt;“Pourquoi des batchs dans Kubernetes ?”&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Oui, aujourd’hui encore,comme j’ai pu l’indiquer précédemment, on doit créer des traitements batchs. A coté des APIs qui représentent le cas d’utilisation “standard” du Cloud, on peut également avoir à traiter des fichiers volumineux allant de plusieurs centaines de Mo à quelques Go.&lt;/p&gt;

&lt;p&gt;Parmi les cas d’utilisation qui nécessitent ce genre de traitement, on pourra avoir:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Les reprises de données (suite à des erreurs ou lors d’une initialisation)&lt;/li&gt;
  &lt;li&gt;Traitement suite à une réception de fichiers (par ex. traitement de fichiers OPENDATA)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Si vous êtes déjà passé sur le Cloud pour vos applications transactionnelles, vous vous poserez cette question: &lt;em&gt;Puis-je également déployer des batchs?&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;pourquoi-se-poser-cette-question&quot;&gt;Pourquoi se poser cette question?&lt;/h3&gt;

&lt;p&gt;Les réponses sont multiples. 
Elles sont tout d’abord liées à une rationalisation des environnements.
Vous avez votre application dans le cloud, votre base de données y est également gérée pour éviter la latence réseau.
Vous devez donc déployer des traitements tiers au plus proche de celle-ci pour vous soustraire des mêmes soucis.&lt;/p&gt;

&lt;p&gt;De plus, l’écosystème lié au cloud offre des technologies et pratiques qui rendent la vie plus simple (si, si, je vous assure) aux développeurs et ops. 
Le déploiement via &lt;a href=&quot;https://en.wikipedia.org/wiki/Infrastructure_as_code&quot;&gt;l’Infra As Code&lt;/a&gt; est un bon exemple : Avoir toute l’infrastructure liée aux traitements batchs et transactionnels versionnées et instantiables à la demande est quelque chose dont on a du mal à se passer!&lt;/p&gt;

&lt;h2 id=&quot;difficultés-par-rapport-aux-apis&quot;&gt;Difficulté(s) par rapport aux APIs&lt;/h2&gt;

&lt;p&gt;Quand on déploie une API dans le cloud, généralement tout va bien. 
On peut voir rapidement que cet environnement convient bien à ce genre de traitements.&lt;/p&gt;

&lt;p&gt;Pour les batchs, c’est une autre affaire!
Selon les sociétés, il peut y avoir un fort historique et beaucoup plus d’exigences que pour les APIs. 
Ces dernières pourront être liées aux performances, à la qualité de service ou plus simplement à l’utilisation.&lt;/p&gt;

&lt;p&gt;Il faut donc, à l’instar de toute architecture, déterminer quel sera l’environnement technique de ce type de traitement. 
Cette fois, on aura à concilier performances, fichiers volumineux et reprises sur erreur.&lt;/p&gt;

&lt;h3 id=&quot;quelques-technologies&quot;&gt;Quelques technologies&lt;/h3&gt;

&lt;p&gt;On pourra retrouver dans notre future architecture les briques suivantes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Une passerelle de fichiers (File Gateway) pour permettre l’envoi des fichiers de manière sécurisée&lt;/li&gt;
  &lt;li&gt;Un stockage objet pour la distribution de fichiers ou l’archivage.&lt;/li&gt;
  &lt;li&gt;Les éléments nécessaires à l’API : bases de données, &lt;a href=&quot;https://en.wikipedia.org/wiki/Hardware_security_module&quot;&gt;HSMs&lt;/a&gt;, Cluster Kubernetes,…&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;modes-de-déclenchement&quot;&gt;Modes de déclenchement&lt;/h2&gt;

&lt;p&gt;Si on regarde de plus près les exigences techniques liées aux cas d’utilisation, on pourrait résumer les différents modes de déclenchement de la manière suivante:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Traitement sur réception de fichiers&lt;/li&gt;
  &lt;li&gt;Traitement déclenché par un ordonnanceur/orchestrateur centralisé (ex. https://dkron.io/) de manière régulière ou non.&lt;/li&gt;
  &lt;li&gt;Traitement déclenché par &lt;a href=&quot;https://en.wikipedia.org/wiki/Cron&quot;&gt;CRON&lt;/a&gt; (qui est un ordonnanceur, mais un peu plus roots)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;J’ai volontairement exclu les traitements sur présence de messages (ex. Kafka). Je les considère plus liés au monde transactionnel.&lt;/p&gt;

&lt;p&gt;Dans les paragraphes suivants, je vais décrire des solutions d’architecture qui permettent de déployer ces traitements dans Kubernetes. J’aborderai sans doute un exemple dans un autre article&lt;/p&gt;

&lt;h2 id=&quot;contraintes&quot;&gt;Contraintes&lt;/h2&gt;

&lt;p&gt;Dès qu’on s’aventure dans ce type de conception, nous aurons, au-delà des &lt;a href=&quot;https://12factor.net/&quot;&gt;12 factors&lt;/a&gt;, les contraintes suivantes à traiter:&lt;/p&gt;

&lt;h3 id=&quot;gestion-des-erreurs-et-indisponibilités&quot;&gt;Gestion des erreurs et indisponibilités&lt;/h3&gt;
&lt;p&gt;Dans un cluster Kubernetes, le crash d’un POD n’est pas rédhibitoire.
Le cluster permet de redémarrer immédiatement une autre instance.&lt;/p&gt;

&lt;p&gt;Pour les APIs, ce n’est pas un problème.
Pour les batchs, c’est une autre paire de manches. 
Quid du crash en plein milieu du traitement d’un fichier?&lt;/p&gt;

&lt;p&gt;Il faut donc penser à ce cas (et à d’autres) et archiver les fichiers pour un éventuel rejeu.&lt;/p&gt;

&lt;h3 id=&quot;données-et-idempotence-des-traitements&quot;&gt;Données et idempotence des traitements&lt;/h3&gt;

&lt;p&gt;Idéalement, les fichiers doivent avoir des lignes indépendantes qui peuvent être insérées individuellement et dans n’importe quel ordre.
Aussi, chaque modification et traitement de données doivent être idempotentes.&lt;/p&gt;

&lt;p&gt;Pourquoi? Pas seulement par ce que c’est sympa et l’état de l’art, mais dans ce nouvel environnement, vous ne pourrez pas forcément garantir l’ordre des traitements.
L’une des solutions potentielles de traitement est de découpler la lecture et l’insertion par du queueing (Artemis, Kafka &lt;em&gt;- oui ce n’est pas du queuing, mais vous avez compris…&lt;/em&gt;). 
Dans ce cas, si votre traitement n’est pas idempotent, vous devrez lutter avec des doublons en base.&lt;/p&gt;

&lt;h3 id=&quot;gestion-des-ressources&quot;&gt;Gestion des ressources&lt;/h3&gt;

&lt;p&gt;Imaginez, vous recevez un fichier de 1Go. 
Vos ressources systèmes sont des PODs avec un 1 Go de RAM.&lt;/p&gt;

&lt;p&gt;Vous voyez le soucis?&lt;/p&gt;

&lt;p&gt;Cet exemple, qui n’est pas trop éloigné de la réalité, mets en évidence l’une des contraintes techniques que vous devrez prendre dès le début de votre conception.&lt;/p&gt;

&lt;p&gt;L’une des solutions serait, par exemple, le traitement quasi systématique du streaming de fichiers et l’obligation d’avoir des fichiers avec des lignes de données indépendantes (c.-à-d. sans avoir à faire de liens inter lignes pendant le traitement).&lt;/p&gt;

&lt;h2 id=&quot;traitement-sur-réception-de-fichiers&quot;&gt;Traitement sur réception de fichiers&lt;/h2&gt;

&lt;p&gt;Dans ce cas, nous avons un processus qui est déclenché lors de la réception d’un fichier. Nous pourrons par exemple avec ce genre d’architecture un fichier qui est envoyé dans espace de stockage objet. Ce dernier est ensuite traité par un programme.
J’ai fait le choix ici de mettre en oeuvre un couplage lâche (on ne se refait pas) entre l’espace de réception de fichiers et le traitement.&lt;/p&gt;

&lt;p&gt;Je traite ici le risque de crash d’un POD en gardant systématiquement les fichiers dans un stockage objet. De cette manière, si le traitement a échoué, un autre POD pourra le télécharger et rejouer le processus batch.&lt;/p&gt;

&lt;p&gt;Ce découplage permet de gérer facilement la scalabilité et les arrêts/relances de PODs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2022/05/batch_evenement-Batch_sur_presence_fichier.svg&quot; alt=&quot;batch_evenement-Batch_sur_presence_fichier&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Dans ce cas, le batch pourra être déployé sous la forme d’un &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&quot;&gt;déploiement Kubernetes&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;traitement-déclenché-à-distance-par-ex-par-un-orchestrateur-de-traitements&quot;&gt;Traitement déclenché à distance (par ex. par un orchestrateur de traitements)&lt;/h2&gt;

&lt;p&gt;Maintenant, on va aborder les traitements qui sont lancés par un ordonnanceur tiers ou tout simplement lancé à distance. 
Généralement, dans le monde de l’entreprise, la planification des traitements est centralisée au lieu de laisser de le faire sur chaque machine avec des &lt;a href=&quot;https://en.wikipedia.org/wiki/Cron&quot;&gt;CRON Jobs&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dans ce cas, on a deux manières de procéder:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Avoir un traitement qui fournit une API permettant de démarrer des traitements et d’avoir leurs statuts.&lt;/li&gt;
  &lt;li&gt;Lancer des jobs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;avec-une-api&quot;&gt;Avec une API&lt;/h3&gt;

&lt;p&gt;Ici, on conçoit les batchs comme des WEBAPPS qui fournissent des traitements batchs sur demande via des APIs. La contrainte est qu’à l’instar de la solution précédente, le programme tourne toujours et n’est vraiment utile que lorsqu’il est appelé via un endpoint REST.&lt;/p&gt;

&lt;p&gt;Ce modèle de conception peut être utilisé à mon avis si la fréquence est forte et si l’intégration d’un Job Kubernetes est problématique pour vous (voir ci-dessous).&lt;/p&gt;

&lt;p&gt;L’un des avantages que l’on pourra trouver est que le &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&quot;&gt;mode de déploiement est assez simple et similaire aux APIs&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2022/05/traitement_api.svg&quot; alt=&quot;traitement_api&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;avec-des-jobs&quot;&gt;Avec des jobs&lt;/h3&gt;

&lt;p&gt;Si votre ordonnanceur peut exécuter le client kubectl, vous pourrez considérer les &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/job/&quot;&gt;jobs  kubernetes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;En résumé, ils permettent de créer un POD et exécute une action en gérant les erreurs potentielles jusqu’à complétion du traitement.&lt;/p&gt;

&lt;p&gt;Par exemple, voici un job permettant de faire un “Hello World!”:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;batch/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Job&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;hello-world&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;helloworld&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;busybox&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;echo&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Hello&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;World!&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;restartPolicy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Never&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;backoffLimit&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Une fois déployé avec Helm, vous pouvez les voir avec la commande &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubectl get jobs&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;minikube kubectl &lt;span class=&quot;nt&quot;&gt;--&lt;/span&gt; get &lt;span class=&quot;nb&quot;&gt;jobs
&lt;/span&gt;NAME          COMPLETIONS   DURATION   AGE
hello-world   0/1           25s        25s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Pour les logs et voir le résultat de la commande lancé, cela se passe d’une manière assez habituelle:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;minikube kubectl &lt;span class=&quot;nt&quot;&gt;--&lt;/span&gt; logs hello-world-zx4wh
Hello World!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;traitement-déclenché-par-cron&quot;&gt;Traitement déclenché par CRON&lt;/h2&gt;

&lt;p&gt;Maintenant, on va laisser le soin au Cluster Kubernetes de lancer les différents traitements via une CRON.
Bien que je ne suis pas trop fan de ne pas centraliser l’ordonnancement, cela peut être très utile si votre plateforme est centrée sur Kubernetes.&lt;/p&gt;

&lt;p&gt;Si vous êtes dans ce cas-là, vous pouvez utiliser l’objet &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/&quot;&gt;CronJob&lt;/a&gt; qui n’est ni plus ni moins qu’un &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/job/&quot;&gt;Job&lt;/a&gt; exécuté de manière périodique.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;batch/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;CronJob&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;hello&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;schedule&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;jobTemplate&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;helloworld-cron&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;busybox&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;echo&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Hello&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;World!&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;restartPolicy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;OnFailure&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;panorama-des-solutions-logicielles-possibles&quot;&gt;Panorama des solutions logicielles possibles&lt;/h2&gt;

&lt;p&gt;Une fois qu’on s’est posé toutes (en tout cas certaines) les questions possibles sur nos exigences techniques et la conception, on peut voir quelles sont les technologies possibles pour implémenter des batchs “cloud natifs”.&lt;/p&gt;

&lt;p&gt;Ça ne sera pas une surprise, je vais m’attarder à la plateforme Java. Il est bien évidemment possible d’utiliser d’autres langages et frameworks tels que Go.&lt;/p&gt;

&lt;p&gt;En Java, vous avez le choix entre différents frameworks :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;[Spring avec spring batch et/ou integration&quot;&gt;Spring avec spring batch&lt;/a&gt; et/ou &lt;a href=&quot;https://spring.io/projects/spring-integration&quot;&gt;integration&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://camel.apache.org/&quot;&gt;Camel&lt;/a&gt; qui peut être utilisé avec &lt;a href=&quot;https://camel.apache.org/manual/spring.html&quot;&gt;Spring&lt;/a&gt; ou &lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt; avec la &lt;a href=&quot;https://github.com/quarkiverse/quarkus-jberet&quot;&gt;JSR 352&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Si vous allez du côté du BigData, vous pouvez aussi envisager d’utiliser des technologies telles qu’&lt;a href=&quot;https://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt;.
Ces dernières vous permettront de &lt;a href=&quot;https://spark.apache.org/docs/latest/running-on-kubernetes.html&quot;&gt;découper “plus facilement” vos traitements&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;le-diable-se-cache-dans-les-détails&quot;&gt;Le diable se cache dans les détails&lt;/h2&gt;

&lt;p&gt;Déployer un batch dans Kubernetes peut se faire assez facilement (en développement) une fois qu’on a compris quelques principes. 
Cependant, les soucis peuvent survenir une fois arrivé en production.&lt;/p&gt;

&lt;p&gt;La gestion des erreurs est beaucoup plus complexe que les APIs. Il vous faudra donc définir avec les différentes parties prenantes quel est le meilleur fonctionnement (rejeu) en production. 
Il vous faudra ainsi bien &lt;a href=&quot;https://blog.touret.info/2022/02/09/analyser-les-risques-pour-mieux-definir-une-architecture/&quot;&gt;identifier et évaluer les risques liés à votre application&lt;/a&gt; et voir quelles sont les actions à mener.&lt;/p&gt;

&lt;p&gt;Aussi, si vous devez manipuler des fichiers volumineux, il faudra faire attention au système de fichiers utilisé et ses performances. Habituellement, avec ce type d’architecture, on utilise généralement du SAN. En fonction de vos exigences, un &lt;a href=&quot;https://www.redhat.com/fr/topics/data-storage/file-block-object-storage&quot;&gt;stockage block&lt;/a&gt; pourra être plus adapté.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Pour conclure cet article, vous aurez compris que le sujet des batchs dans Kubernetes peut s’avérer assez complexe à gérer. 
Au-delà des technologies qui peuvent faire le job (&lt;em&gt;désolé du mauvais jeu de mots&lt;/em&gt;), il vous faudra faire très attention à tout l’environnement dans lequel votre programme devra interagir. Les bases, le réseau, les performances de votre matériel seront des prérequis indispensables.&lt;/p&gt;

&lt;p&gt;Aussi, il vous faudra faire attention à la manière dont sont transmises les données et dont vous les traitez. 
Bref, il faut étudier la solution dans son ensemble du développement à l’exploitation pour s’assurer de ne rien oublier.&lt;/p&gt;

&lt;p&gt;Enfin, cet article n’est bien évidemment pas exhaustif que cela soit sur les solutions ou les contraintes à adresser. 
J’ai néanmoins essayé d’apporter quelques cas concrets et retours d’expérience.&lt;/p&gt;

&lt;p&gt;J’essaierai de détailler un cas concret dans un prochain article.&lt;/p&gt;</content><author><name>Alexandre Touret</name></author><category term="cloud" /><category term="kubernetes" /><category term="batch" /><summary type="html">Quand on parle du Cloud et de Kubernetes, généralement on pense aux APIs. Mais qu’en est-il des batchs?</summary></entry></feed>